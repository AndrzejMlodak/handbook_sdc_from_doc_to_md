<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>microdata-03-risk-assessment</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="_03-microdata-03-Risk-assessment_files/libs/clipboard/clipboard.min.js"></script>
<script src="_03-microdata-03-Risk-assessment_files/libs/quarto-html/quarto.js"></script>
<script src="_03-microdata-03-Risk-assessment_files/libs/quarto-html/popper.min.js"></script>
<script src="_03-microdata-03-Risk-assessment_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="_03-microdata-03-Risk-assessment_files/libs/quarto-html/anchor.min.js"></script>
<link href="_03-microdata-03-Risk-assessment_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="_03-microdata-03-Risk-assessment_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="_03-microdata-03-Risk-assessment_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="_03-microdata-03-Risk-assessment_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="_03-microdata-03-Risk-assessment_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="risk-assessment" class="level2">
<h2 class="anchored" data-anchor-id="risk-assessment">Risk assessment</h2>
<section id="overview" class="level3">
<h3 class="anchored" data-anchor-id="overview">Overview</h3>
<!--**SECTION 3.2.1 LUISA COULD PERHAPS ADD SOMETHING IN THIS SECTION FROM THE MATERIALS IN THE INTRODUCTION OF THE RECORD LINKAGE PDF, SECTION 1 OF THAT PDF (remark by Josep)**-->
<p>Microdata has many analytical advantages over aggregated data, but also poses more serious disclosure issues because of the many variables that are disseminated in one file. For microdata, disclosure occurs when there is a possibility that an individual can be re-identified by an intruder using information contained in the file, and when on the basis of that, confidential information is obtained. Microdata are released only after taking out directly identifying variables, such as names, addresses, and identity numbers. However, other variables in the microdata can be used as indirect identifying variables. For individual microdata this are variables such as gender, age, occupation, place of residence, country of birth, family structure, etc. and for business microdata variables such as economic activity, number of employees, etc. These (indirect) identifying variables are mainly publicly available variables or variables that are present in public databases such as registers.</p>
<p>If the identifying variables are categorical then the compounding (cross-classification) of these variables defines a key. The disclosure risk is a function of such identifying variables/keys either in the sample alone or in both the sample and the population.</p>
<p>To assess the disclosure risk, we first need to make realistic assumptions about what an intruder might know about respondents and what information will be available to him to match against the microdata and potentially make an identification and disclosure. These assumptions are known as disclosure risk scenarios and more details and examples are provided in the next section of this handbook. Based on the disclosure risk scenario, the identifying variables are determined. The other variables in the file are confidential or sensitive variables and represent the data not to be disclosed. NSIs usually view all non-publicly available variables as confidential/sensitive variables regardless of their specific content, though there can be some variables, e.g.&nbsp;sexual identity, health conditions, income, that can be more sensitive.</p>
<p>In order to undertake a risk assessment of microdata, NSIs might rely on <em>ad-hoc</em> methods, experience and checklists based on assessing the detail and availability of identifying variables. There is a clear need for obtaining quantitative and objective disclosure risk measures for the risk of re-identification in the microdata. For microdata containing censuses or registers, the disclosure risk is known as we have all identifying variables available for the whole population. However, for microdata containing samples the population base is unknown or partially known through marginal distributions. Therefore, probabilistic modelling or heuristics are used to estimate disclosure risk measures at population level, based on the information available in the sample. This section provides an overview of methods and tools that are available in order to estimate quantitative disclosure risk measures.</p>
<p>Intuitively, a unit is at risk if we are able to single it out from the rest. The idea at the base of the definition of risk is a way to measure rareness of a unit either in the sample or in the population.</p>
<p>When the identifying variables are categorical (as it is usually the case in social surveys) the risk is cast in terms of the cells of the contingency table built by cross-tabulating the identifying variables: the keys. Consequently all the records in the same cell have the same value of the risk.</p>
<p><em>A classification of risk measures</em><br>
Several definitions of risk have been proposed in the literature; here we focus mainly on those for which tools are available to compute/estimate them easily. We can broadly classify disclosure risk measures into three types: risk measures based on keys in the sample, those based on keys in the population and that make use of statistical models or heuristics to estimate the quantities of interest and those based on the theory of record linkage. Whereas the first two classes are devoted to risk assessment for categorical identifying variables the third one may be used for categorical and continuous variables.</p>
<p><em>Risk based on keys in the sample</em><br>
For the first class of risk measures a unit is at risk if its combination of scores on the identifying variables is below a given threshold. The threshold rule used within the software package μ‑ARGUS, as presented in Section , is an example of this class of risk measures.</p>
<p><em>Risk based on keys in the population</em><br>
For the second type of approach we are concerned with the risk of a unit as determined by its combination of scores on the identifying variables within the population or its probability of re-identification. The idea then is that a unit is at risk if such quantity is above a given threshold. Because the frequency in the population is generally unknown, it may be estimated through a modelling process. Examples of this reasoning are the individual risk of disclosure based on the Negative Binomial distribution developed by Benedetti and Franconi (1998) and Franconi and Polettini (2004), which is outlined in Section 3.3.5, and the one based on the Poisson distribution and log-linear models developed by Skinner and Holmes (1998) and Elamir and Skinner (2004) which is described in Section 3.3.6 along with current research on other probabilistic methods. Another approach based on keys in the population is the Special Uniques Detection (SUDA) Algorithm developed by Elliot et al.&nbsp;(2002) that uses a heuristic method to estimate the risk; this is outlined in Section 3.3.7.</p>
<p><em>Risk based on record linkage</em><br>
When identifying variables are continuous we cannot exploit the concept of rareness of the keys and we transform such concept into rareness in the neighbourhood of the record. A way to measure rareness in the neighbourhood is through record linkage techniques. This third class of disclosure risk is covered in Section 3.3.8.</p>
<p>Section 3.3.2 provides an introduction to disclosure risk scenarios and Section 3.2.3 introduces concepts and notation used throughout this chapter. Sections to 3.3.8 describe different approaches to microdata risk assessment as specified above. However, as microdata risk assessment is a novelty in statistical research there isn’t yet agreement on what method is the best, or at least best under given circumstances. In the following sections we comment on various approaches to risk measures and try to give advice on situations where they could or could not be applied. In any case, it has been recognised that research should be undertaken to evaluate these different approaches to microdata risk assessment, see for example Shlomo and Barton (2006).</p>
<p>The focus of these methods and this section of the handbook is for microdata samples from social surveys. For microdata samples from censuses or registers the disclosure risk is known. Business survey microdata are not typically released due to their disclosive nature (skewed distributions and very high sampling fractions).</p>
<p>In section 1.1 we make some suggestions on practical implementation and in section 3.8 we give examples of real data sets and ways in which risk assessment could be carried out.</p>
</section>
<section id="disclosure-risk-scenarios" class="level3">
<h3 class="anchored" data-anchor-id="disclosure-risk-scenarios">Disclosure risk scenarios</h3>
<p><em>Need to add section from Luisa. My feeling is that as it stands this was quite long and could be simplified.</em></p>
<p><em>Ok, but later … when we will be close to the final version</em></p>
<p>The definition of a disclosure scenario is a first step towards the development of a strategy for producing a “safe” microdata file (MF). A scenario synthetically describes (i) which is the information potentially available to the intruder, and (ii) how the intruder would use such information to identify an individual i.e.&nbsp;the intruder’s attack means and strategy. Often, defining more than one scenario might be convenient, because different sources of information might be alternatively or simultaneously available to the intruder. Moreover, re-identification risk can be assessed keeping into account different scenarios at the same time.</p>
<p>We refer to the information available to the intruder as an External Archive (EA), where information is provided at individual level, jointly with directly identifying data, such as name, surname, etc. The disclosure scenario is based on the assumption that the EA available to the intruder is an individual microdata archive. That is, for each individual directly identifying variables, and some other variables are available. Some of these further variables are assumed to be available also in the MF that we want to protect. The intruder’s strategy of attack would be to use this overlapping information to match direct identifier to a record in the MF. The matching variables are then the <em>identifying variables</em>.</p>
<p>We consider two different types of re-identification, <em>spontaneous recognition</em> and <em>re-</em>identification <em>via record matching</em> (or <em>linkage</em>) according to the information we assume to be available to the intruder. In the first case we consider that the intruder might rely on personal knowledge about one or a few target individuals, and spontaneously recognize a surveyed individual (<em>Nosy Neighbour scenario</em>). In such a case the External Archive contains one (or a few) records relative to <em>detailed</em> personal information. In the second case, we assume that the intruder (who might be an MF user) has access to a <em>public register</em> and that he or she tries to match the information provided by this EA, with that provided by the MF, in order to identify surveyed units. In such a case, the intruder’s chance of identifying a unit depends on the EA main characteristics, such as completeness, accuracy and data classification. Broadly speaking, we assume that the intruder has a lower chance of correctly identifying an individual when the information provided by the EA is not update, complete, accurate, or is classified according to standards different by those used in the statistical survey.</p>
<p>Moreover, as far as statistical disclosure control is concerned, experts are used to distinguish between social and economic microdata (without loss of generality we can consider respectively individuals and enterprises). In fact, the concept of disclosure risk is mainly based on the idea of rareness with respect to a set of identifying variables. For social survey microdata, because of the characteristics of the population under investigation and the nature of the data collected, identifying variables are mainly (or exclusively) categorical. For much of the information collected on enterprises however the identifying variables often take the form of quantitative variables with asymmetric distributions (Willenborg and de Waal, 2001). Disclosure scenarios are then described according to this statement.</p>
<p>The case study part of the Handbook&nbsp; contains examples of the Nosy Neighbour scenario and the EA scenario for social survey data. The issues involved with hierarchical and longitudinal data are also addressed. Finally, scenarios for business survey data are discussed.</p>
<p>In any case the definition of the scenario is essential as it defines the hypothesis underneath the risk estimation and the subsequent protection of the data.</p>
</section>
<section id="concepts-and-notation" class="level3">
<h3 class="anchored" data-anchor-id="concepts-and-notation">Concepts and notation</h3>
<p>For microdata, disclosure risk measures quantify the risk of re-identification. Individual per record disclosure risk measures are useful for identifying high-risk records and targeting the SDC methods. These individual risk measures can be aggregated to obtain global file level disclosure risk measures. These global risk measures are particularly useful to NSIs for their decision making process on whether the microdata is safe to be released and allows comparisons across different files.</p>
<p><em>Microdata disclosure</em><br>
Disclosure in a microdata context means a correct record re-identification operation that is achieved by an intruder when comparing a target individual in a sample with an available list of units (external file) that contains individual identifiers such as name and address plus a set of identifying variables. Re-identification occurs when the unit in the released file and a unit in the external file belong to the same individual in the population. The underlying hypothesis is that the intruder will always try to match a unit in the sample <span class="math inline">\(s\)</span> to be released and a unit in the external file using the identifying variables only. In addition, it is likely that the intruder will be interested in identifying those sample units that are unique on the identifying variables. A re-identification occurs when, based on a comparison of scores on the identifying variables, a unit <span class="math inline">\(i^*\)</span> in the external file is selected as matching to a unit <span class="math inline">\(i\)</span> in the sample and this link is correct and therefore confidential information about the individual is disclosed using the direct identifiers.</p>
<p>To define the disclosure scenario, the following assumptions are made. Most of them are conservative and contribute to the definition of a worst case scenario:</p>
<ol type="1">
<li><p>a sample <span class="math inline">\(s\)</span> from a population <span class="math inline">\(\mathcal{P}\)</span> is to be released, and sampling design weights are available;</p></li>
<li><p>the external file available to the intruder covers the whole population <span class="math inline">\(\mathcal{P}\)</span>; consequently for each <span class="math inline">\(i \in s\)</span>, the matching unit <span class="math inline">\(i^*\)</span> does always exist in <span class="math inline">\(\mathcal{P}\)</span>;</p></li>
<li><p>the external file available to the intruder contains the individual direct identifiers and a set of categorical identifying variables that are also present in the sample;</p></li>
<li><p>the intruder tries to match a unit <span class="math inline">\(i\)</span> in the sample with a unit <span class="math inline">\(i^*\)</span> in the population register by comparing the values of the identifying variables in the two files;</p></li>
<li><p>the intruder has no extra information other than that contained in the external file;</p></li>
<li><p>a re-identification occurs when a link between a sample unit <span class="math inline">\(i\)</span> and a population unit <span class="math inline">\(i^*\)</span> is established and <span class="math inline">\(i^*\)</span> is actually the individual of the population from which the sampled unit <span class="math inline">\(i\)</span> was derived; e.g.&nbsp;the match has to be a correct match before an identification takes place.</p></li>
</ol>
<p>Moreover we add the following assumptions:</p>
<ol start="7" type="1">
<li><p>the intruder tries to match all the records in the sample with a record in the external file;</p></li>
<li><p>the identifying variables agree on correct matches, that is no errors, missing values or time-changes occur in recording the identifying variables in the two microdata file.</p></li>
</ol>
<p><em>Notation</em><br>
The following notation is introduced here and used throughout the chapter when describing different methods for estimating the disclosure risk of microdata.</p>
<p>Suppose the key has <span class="math inline">\(K\)</span> cells and each cell <span class="math inline">\(k = 1, \ldots, K\)</span> is the cross-product of the categories of the identifying variables. In general, we will be looking at a contingency table spanned by the identifying variables in the microdata and not a single vector. The contingency table contains the sample counts and is typically very large and very sparse. Let the population size in cell <span class="math inline">\(k\)</span> of the key be <span class="math inline">\(F_k\)</span> and the sample size <span class="math inline">\(f_k\)</span>. Also:</p>
<p><span class="math display">\[
\sum_{k = 1}^{K}F_{k} = N,\quad \sum_{k = 1}^{K}f_{k} = n.
\]</span></p>
<p>Formally the sample and population sizes in the models introduced in sections 3.3.5 and 3.3.6 are random and their expectations are denoted by n and N respectively. In practice, the sample and population size are usually replaced by their natural estimators; the actual sample and population sizes, assumed to be known.</p>
<p>Observing the values of the key on individual <span class="math inline">\(i \in s\)</span> will classify such individual into one cell. We denote by <span class="math inline">\(k(i)\)</span> the index of the cell into which individual <span class="math inline">\(i \in s\)</span> is classified based on the values of the key.</p>
<p>According to the concept of re-identification disclosure given above, we define the (base) individual risk of disclosure of unit <span class="math inline">\(i\)</span> in the sample as its probability of re-identification under the worst case scenario. Therefore the risk <span class="math inline">\(r_i\)</span> that we get is certainly not smaller than the actual risk, the individual risk is a conservative estimate of the actual risk:</p>
<p><span class="math display">\[
r_{i}=\mathbb{P}\left( i \text{ correctly linked with } i^* \mid s , \mathcal{P} \text{, worst case scenario }\right) \qquad\text{(3.2.3.1)}
\]</span></p>
<p>All of the methods based on keys in the population described in this chapter aim to estimate this individual per-record disclosure risk measure that can be formulated as <span class="math inline">\(1/F_k\)</span>. The population frequencies <span class="math inline">\(F_k\)</span> are unknown parameters and therefore need to be estimated from the sample. A global file-level disclosure risk measure can be calculated by aggregating the individual disclosure risk measures over the sample:</p>
<p><span class="math display">\[
\tau_{1} = \sum\limits_{k}^{}\frac{1}{F_{k}}
\]</span></p>
<p>An alternative global risk measure can be calculated by aggregating the individual disclosure risk measures over the sample uniques of the cross-classified identifying variables. Since the uniques in the population <span class="math inline">\(F_k = 1\)</span>, are the dominant factor in the disclosure risk measure, we focus our attention on sample uniques <span class="math inline">\(f_k = 1\)</span>:</p>
<p><span class="math display">\[
\tau_{2} = \sum\limits_{k}^{}{I(f_{k} = 1)\frac{1}{F_{k}}}
\]</span></p>
<p>where <span class="math inline">\(I\)</span> represents an indicator function obtaining the value 1 if <span class="math inline">\(f_k = 1\)</span> or 0 if not.</p>
<p>Both of these global risk measures can also be presented as rates by dividing by <span class="math inline">\(n\)</span>, the sample size or the number of uniques.</p>
<p>We assume that the <span class="math inline">\(f_k\)</span> are observed but the <span class="math inline">\(F_k\)</span> are not observed.</p>
</section>
<section id="argus-threshold-rule" class="level3">
<h3 class="anchored" data-anchor-id="argus-threshold-rule">ARGUS threshold rule</h3>
<p>The ARGUS threshold rule is based on easily applicable rules and views of safety/unsafety of microdata that is used at Statistics Netherlands. The implementation of these rules was the main reason to start the development of the software package μ‑ARGUS.</p>
<p>In a disclosure scenario, keys a combination of identifying variables, are supposed to be used by an intruder to re-identify a respondent. Re-identification of a respondent can occur when this respondent is rare in the population with respect to a certain key value, i.e.&nbsp;a combination of values of identifying variables. Hence, rarity of respondents in the population with respect to certain key values should be avoided. When a respondent appears to be rare in the population with respect to a key value, then disclosure control measures should be taken to protect this respondent against re-identification.</p>
<p>Following the Nosy Neighbour scenario, the aim of the μ‑ARGUS threshold rule is to avoid the occurrence of combinations of scores that are rare in the population and not only avoiding population-uniques. To define what is meant by rare the data protector has to choose a threshold value for each key. If a key occurs more often than this threshold the key is considered safe, otherwise the key must be protected because of the risk of re-identification.</p>
<p>The level of the threshold and the number and size of the keys to be inspected depend of course on the level of protection you want to achieve. Public use files require much more protection than microdata files under contract that are only available to researchers under a contract. How this rule is used in practice is given in the example of section 3.7</p>
<p>If a key is considered unsafe according to this rule, protection is required. Therefore often global recoding and local suppression are applied. These techniques are described in the sections 3.4.3.2 and 3.4.3.4</p>
</section>
<section id="argus-individual-risk-methodology" class="level3">
<h3 class="anchored" data-anchor-id="argus-individual-risk-methodology">ARGUS individual risk methodology</h3>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Expert level</p>
</div>
</div>
</div>
<blockquote class="blockquote">
<p>If a distinction between units rare in the sample from a unit rare in the population wants to be made then an inferential step may be followed. In the initial proposal by Benedetti and Franconi (1998), further developed in Franconi and Polettini (2004) and implemented in μ‑ARGUS, the uncertainty on <span class="math inline">\(F_k\)</span> is accounted for in a Bayesian fashion by introducing the distribution of the population frequencies given the sample frequencies. The individual risk of disclosure is then measured as the (posterior) mean of <span class="math inline">\(\frac{1}{F_k}\)</span> with respect to the distribution of <span class="math inline">\(F_k|f_k\)</span>:</p>
<p><span class="math display">\[
r_{i} = \mathbb{E} \left( \frac{1}{F_{k}} \mid f_{k} \right) = \sum\limits_{h\geq f_{k}} \frac{1}{h} \mathbb{P} \left(F_{k} = h \mid f_{k} \right). \qquad\text{(3.2.5.1)}
\]</span></p>
<p>where the posterior distribution of <span class="math inline">\(F_k|f_k\)</span> is negative binomial with success probability <span class="math inline">\(p_k\)</span> and number of successes <span class="math inline">\(f_k\)</span>. As the risk is a function of <span class="math inline">\(f_k\)</span> and <span class="math inline">\(p_k\)</span> its estimate can be obtained by estimating <span class="math inline">\(p_k\)</span>. Benedetti and Franconi (1998) propose to use</p>
<p><span class="math display">\[
{\hat{p}}_{k} = \frac{f_{k}}{\sum\limits_{i:k(i)=k}^{}w_{i}} \qquad \text{(3.2.5.2)}
\]</span></p>
<p>where <span class="math inline">\(\sum\limits_{i:k(i)=k}^{}w_{i}\)</span> is an estimate of <span class="math inline">\(F_k\)</span> based on the sampling design weights <span class="math inline">\(w_i\)</span>, possibly calibrated (Deville and Särndal, 1992).</p>
<p><em>When is it possible to apply the individual risk estimation</em><br>
The procedure relies on the assumption that the available data are a sample from a larger population. <em>If the sampling weights are not available, or if data represent the whole population, the strategy used to estimate the individual risk is not meaningful</em>.</p>
<p>In the μ‑ARGUS manual (Hundepool <em>et al.</em>, 2004) a fully detailed description of the approach is reported. This brief note is based on Polettini (2004).</p>
<p><em>Assessing the risk for the whole file</em><br>
The individual risk provides a measure of risk <em>at the individual level</em>. A <em>global</em> measure of disclosure risk for the whole file can be expressed in terms of the expected number of re-identifications in the file. The <em>expected number of re</em>-<em>identifications</em> is a measure of disclosure that depends on the number of records. For this reason, μ‑ARGUS evaluates also the <em>re‑identification rate</em> that is independent of <span class="math inline">\(n\)</span>:</p>
<p><span class="math display">\[
\xi = \frac{1}{n}\sum\limits_{k=1}^{K}{f_{k}r_{k}} \quad .
\]</span></p>
<p><span class="math inline">\(\xi\)</span> provides a measure of <em>global risk, i.e.</em> a measure of disclosure risk for the whole file, which does not depend on the sample size and can be used to assess the risk of the file or to compare different types of release; for the mathematical details see Polettini (2004).</p>
<p>The <em>percentage of expected re-identifications</em>, i.e.&nbsp;the value <span class="math inline">\(\psi=100\cdot\xi\%\)</span> provides an equivalent measure of global risk.</p>
<p><em>Application of local suppression within the individual risk methodology</em><br>
After the risk has been estimated, protection takes place. One option in protection is the application of <em>local suppression</em> (see Section 3.4.3.4).</p>
<p>In μ‑ARGUS the technique of local suppression, when combined with the individual risk, is applied only to unsafe cells or combinations. Therefore, the user must input a <em>threshold</em> in terms of risk, e.g.&nbsp;probability of re-identification, to classify these as either safe or unsafe. Local suppression is applied to the unsafe individuals, so as to lower their probability of being re‑identified under the given threshold.</p>
<p>In order to select the risk threshold, that represents a level of <em>acceptable risk,</em> i.e.&nbsp;a risk value under which an individual can be considered safe, the <em>re‑identification rate</em> can be used. A <em>release</em> will be considered <em>safe</em> when the expected rate of correct re-identifications is below a level the NSI considers acceptable. As the re-identification rate is cast in terms of the individual risk, a threshold on the re-identification rate can be transformed into a threshold on the individual risk (see below). Under this approach, individuals are at risk because their probability of re-identification contributes a large proportion of expected re-identifications in the file.</p>
<p>In order to reduce the number of local suppressions, the procedure of releasing a safe file considers preliminary steps of protection using techniques such as <em>global recoding</em> (see Section 3.4.3.2). Recoding of selected variables will indeed lower the individual risk and therefore the re-identification rate of the file.</p>
<p><em>Threshold setting using the re-identification rate</em><br>
Consider the re-identification rate <span class="math inline">\(\xi\)</span>: a key <span class="math inline">\(k\)</span> contributes to <span class="math inline">\(\xi\)</span> an amount <span class="math inline">\(r_kf_k\)</span> of expected re‑identifications. Since units belonging to the same key <span class="math inline">\(k\)</span> have the same individual risk, keys can be arranged in increasing order of risk <span class="math inline">\(r_k\)</span>. Let the subscript (<span class="math inline">\(k\)</span>) denotes the <span class="math inline">\(k\)</span>-th element in this ordering. A threshold <span class="math inline">\(r^*\)</span> on the individual risk can be set. Consequently, unsafe cells are those for which <span class="math inline">\(r_{k} \geq r^*\)</span> that can be indexed by <span class="math inline">\((k) = k^{*} + 1,\ldots,K\)</span>. The key <span class="math inline">\(k^{*}\)</span> is in a one-to-one correspondence to <span class="math inline">\(r^{*}\)</span>. This allows setting an upper bound <span class="math inline">\(\xi^{*}\)</span> on the re‑identification rate of the released file (after data protection) substituting <span class="math inline">\(r_kf_k\)</span> with <span class="math inline">\(r^{*}f_{(k)}\)</span> for each (<span class="math inline">\(k\)</span>). For the mathematical details see Polettini (2004) and the Argus manual (Hundepool <em>et al.</em>, 2004).</p>
<p>The approach pursued so far can be reversed. Therefore, selecting a <em>threshold</em> <span class="math inline">\(\tau\)</span> <em>on the re-identification rate</em> <span class="math inline">\(\xi\)</span> determines a key index <span class="math inline">\(k^{*}\)</span> which corresponds to a value for <span class="math inline">\(r^{*}\)</span>. Using <span class="math inline">\(r^{*}\)</span> as a threshold for the individual risk keeps the re‑identification rate <span class="math inline">\(\xi\)</span> of the released file below <span class="math inline">\(\tau\)</span>. The search of such a <span class="math inline">\(k^{*}\)</span> is performed by a simple iterative algorithm.</p>
<p><em>Releasing hierarchical files</em><br>
A relevant characteristic of social microdata is its inherent hierarchical structure, which allows us to recognise groups of individuals in the file, the most typical case being the <em>household</em>. When defining the re-identification risk, it is important to take into account this dependence among units: indeed re-identification of an individual in the group may affect the probability of disclosure of all its members. So far, implementation of a hierarchical risk has been performed only with reference to households, i.e.&nbsp;a <em>household risk</em>.</p>
<p>Allowing for dependence in estimating the risk enables us to attain a higher level of safety than when merely considering the case of independence.</p>
<p><em>The household risk</em><br>
The household risk makes use of the same framework defined for the individual risk. In particular, the concept of re-identification holds with the additional assumption that <em>the intruder attempts a confidentiality breach by re-identification of individuals in households</em>.</p>
<p>The <em>household risk</em> is defined as the probability that <em>at least</em> one individual in the household is re-identified. For a given household <span class="math inline">\(g\)</span> of size <span class="math inline">\(|g|\)</span>, whose members are labelled <span class="math inline">\(i_1, \ldots, i_{|g|}\)</span>, the household risk is:</p>
<p><span class="math display">\[
r^{h}(g) = \mathbb{P} \left(i_{1} \cup i_{2} \cup \ldots \cup i_{|g|} \text { re-identified } \right)
\]</span></p>
<p>and is the same for all the individuals in household <span class="math inline">\(g\)</span> and equals <span class="math inline">\(r_{g}^{h}\)</span>.</p>
<p><em>Threshold setting for the household risk</em><br>
Since all the individuals in a given household have the same household risk, the expected number of re‑identified records in household <span class="math inline">\(g\)</span> equals <span class="math inline">\(|g|r_{g}^{h}\)</span>. The re‑identification rate in a hierarchical file can be then defined as <span class="math inline">\(\xi^{h} = \frac{1}{n}\sum\limits_{g=1}^{G}{|g|r_{g}^{h}}\)</span>, where <span class="math inline">\(G\)</span> is the total number of households in the file. The re‑identification rate can be used to define a threshold <span class="math inline">\(r^{h^{\ast}}\)</span> on the household risk <span class="math inline">\(r^{h}\)</span>, much in the same way as for the individual risk. For the mathematical details see Polettini (2004) and the Argus manual (Hundepool <em>et al.</em>, 2004).</p>
<p>Note that the household risk <span class="math inline">\(r_{g}^{h}\)</span> of household <span class="math inline">\(g\)</span> is computed by the individual risks of its household members. For a given household, it might happen that a household is unsafe (<span class="math inline">\(r_{g}^{h}\)</span> exceeds the threshold) because just one of its members, <span class="math inline">\(i\)</span>, say, has a high value <span class="math inline">\(r_{i}\)</span> of the individual risk. To protect the households, the followed approach is therefore to protect individuals in households, first protecting those individuals who contribute most to the household risk. For this reason, inside <em>unsafe households</em>, detection of <em>unsafe individuals</em> is needed. In other words, the threshold on the household risk <span class="math inline">\(r^{h}\)</span> has to be transformed into a threshold on the individual risk <span class="math inline">\(r_{i}\)</span>. To this aim, it can be noticed that the household risk is bounded by the sum of the individual risks of the members of the household: <span class="math inline">\(r_{g}^{h} \leq \sum\limits_{j=1}^{|g|}r_{i_{j}}\)</span>.</p>
<p>Consider to apply a threshold <span class="math inline">\(r^{h^{\ast}}\)</span> on the household risk. In order for household <span class="math inline">\(g\)</span> to be classified safe (i.e.&nbsp;<span class="math inline">\(r_{g}^{h} &lt; r^{h^{\ast}}\)</span>) it is <em>sufficient</em> that all of its components have individual risk less than <span class="math inline">\(\delta_{g} = r^{h ^{\ast}}/|g|\)</span>.</p>
<p>This is clearly an approach possibly leading to overprotection, as we check whether a <em>bound</em> on the household risk is below a given threshold.</p>
<p>It is important to remark that the threshold <span class="math inline">\(δ_g\)</span> just defined depends on the size of the household to which individual <span class="math inline">\(i\)</span> belongs. This implies that for two individuals that are classified in the same key <span class="math inline">\(k\)</span> (and therefore have the same individual risk <span class="math inline">\(r_{k}\)</span>), but belong to different households with different sizes, it might happen that one is classified safe, while the other unsafe (unless the household size is included in the set of identifying variables).</p>
<p>In practice, denoting by <span class="math inline">\(g(i)\)</span> the household to which record <span class="math inline">\(i\)</span> belongs, the approach pursued so far consists in turning a threshold <span class="math inline">\(r^{h^{\ast}}\)</span> on the household risk into a <em>vector of thresholds</em> on the <em>individual risks</em> <span class="math inline">\(r_{i} = 1,\ldots,n\)</span>:</p>
<p><span class="math display">\[
\delta_{g} = \delta_{g(i)} = \frac{r^{h^{\ast}}}{|g(i)|} \quad .
\]</span></p>
<p><em>Individuals</em> are finally set to unsafe whenever <span class="math inline">\(r_{i} \geq \delta_{g(i)}\)</span>; local suppression is then applied to those records, if requested. Suppression of these records ensures that after protection the household risk is below the threshold <span class="math inline">\(\delta_{g}\)</span>.</p>
<p><em>Choice of identifying variables in hierarchical files</em><br>
For household data it is important to include in the identifying variables that are used to estimate the household risks also the available information on the household, such as the number of components or the household type.</p>
Suppose one computes the risk using the household size as the only identifying variable in a household data file, and that such file contains households whose risk is above a fixed threshold. Since information on the number of components in the household cannot be removed from a file with household structure, these records cannot be safely released, and no suppression can make them safe. This permits to check for presence of very peculiar households (usually, the very large ones) that can be easily recognised in the population just by their size and whose main characteristic, namely their size, can be immediately computed from the file. For a discussion on this issue see Polettini (2004).
</blockquote>
</section>
<section id="the-poisson-model-with-log-linear-modelling" class="level3">
<h3 class="anchored" data-anchor-id="the-poisson-model-with-log-linear-modelling">The Poisson model with log-linear modelling</h3>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Expert level</p>
</div>
</div>
</div>
<blockquote class="blockquote">
<p>As defined in Skinner and Elamir (2004), assuming that the <span class="math inline">\(F_{k}\)</span> are independently Poisson distributed with means <span class="math inline">\(\left\{\lambda_{k} \right\}\)</span> and assuming a Bernoulli sampling scheme with equal selection probably <span class="math inline">\(\pi\)</span>, then <span class="math inline">\(f_{k}\)</span> and <span class="math inline">\(F_{k} - f_{k}\)</span> are independently Poisson distributed as: <span class="math inline">\(f_{k} \mid \lambda_{k} \sim \operatorname{Pois} \left(\pi\lambda_{k} \right)\)</span> and <span class="math inline">\(F_{k} - f_{k} \mid \lambda_{k} \sim \operatorname{Pois} \left( ( 1 - \pi ) \lambda_{k} \right)\)</span> . The individual risk measure for a sample unique is defined as <span class="math inline">\(r_{k} = \mathbb{E}_{\lambda_{k}} \left( \frac{1}{F_{k}} \mid f_{k} = 1 \right)\)</span> which is equal to:</p>
<p><span class="math display">\[
r_{k} = \frac{1}{\lambda_{k} (1 - \pi) } \left[ 1 - e^{ - \lambda_{k} (1 - \pi) } \right]
\]</span></p>
<p>In this approach the parameters <span class="math inline">\(\left\{ \lambda_{k} \right\}\)</span> are estimated by taking into account the structure and dependencies in the data through log-linear modelling. Assuming that the sample frequencies <span class="math inline">\(f_{k}\)</span> are independently Poisson distributed with a mean of <span class="math inline">\(u_{k} = \pi\lambda_{k}\)</span>, a log-linear model for the <span class="math inline">\(u_{k}\)</span> can be expressed as: <span class="math inline">\(\text{log}(u_{k}) = x_{k}^{'}\beta\)</span> where <span class="math inline">\(x_{k}\)</span> is a design vector denoting the main effects and interactions of the model for the key variables. Using standard procedures, such as iterative proportional fitting, we obtain the Poisson maximum-likelihood estimates for the vector <span class="math inline">\(\beta\)</span> and calculate the fitted values: <span class="math inline">\({\hat{u}}_{k} = \text{exp}(x_{k}^{'}\hat{\beta})\)</span>. The estimate for <span class="math inline">\({\hat{\lambda}}_{k}\)</span> is equal to <span class="math inline">\(\frac{{\hat{u}}_{k}}{\pi}\)</span> which is substituted for <span class="math inline">\(\lambda_{k}\)</span> in the above formula for <span class="math inline">\(r_{k}\)</span>. The individual disclosure risk measures can be aggregated to obtain a global (file-level) measure:</p>
<p><span class="math display">\[
{\hat{\tau}}_{2} = \sum\limits_{k \in \text{SU}}^{}{\hat{r_k} =}\sum\limits_{k \in \text{SU}}^{}{\frac{1}{{\hat{\lambda}}_{k}(1 - \pi)}\lbrack 1 - e^{- {\hat{\lambda}}_{k}(1 - \pi)}\rbrack}
\]</span></p>
<p>where <span class="math inline">\(\text{SU}\)</span> is the set of all sample uniques.</p>
<p>More details on this method are available from Skinner and Shlomo (2005, 2006) and Shlomo and Barton (2006).</p>
<p>Skinner and Shlomo (2005, 2006) have developed goodness-of-fit criteria for selecting the most robust log-linear model that will provide accurate estimates for the global disclosure risk measure detailed above. The method begins with a log-linear model where a high test statistic indicates under-fitting (i.e., the disclosure risk measures will be over-estimated). Then a forward search algorithm is employed by gradually adding in higher order interaction terms into the model until the test statistic approaches the level (based on a Normal distribution approximation) where the fit of the log-linear model is accepted.</p>
<p>This method is still under development. At present there is a need to develop clear and user-friendly software to implement the method. However, the Office for National Statistics in the UK has used it to inform microdata release decisions. The method is based on theoretical well-defined disclosure risk measures and goodness of fit criteria which ensure the fit of the log-linear model and the accuracy of the disclosure risk measures. It requires a model search algorithm which takes some computer time and requires intervention.</p>
<p>New methods for probabilistic risk assessment are under development based on a generalized Negative Binomial smoothing model for sample disclosure risk estimation which subsumes both the model used in μ‑ARGUS and the Poisson log-linear model above. The method is useful for key variables that are ordinal where local neighbourhoods can be defined for inference on cell <span class="math inline">\(k\)</span>. The Bayesian assumption of <span class="math inline">\(\lambda_{k} \sim \text{Gamma}(\alpha_{k},\beta_{k})\)</span> is added independently to the Poisson model above which then transforms the marginal distribution to the generalized Negative Binomial Distribution: <span class="math display">\[
f_{k} \sim \text{NB}(\alpha_{k},p_{k} = \frac{1}{1 + \text{N}\pi_{k}\beta_{k}})
\]</span> and</p>
<p><span class="math display">\[
F_{k}|f_{k} \sim \text{NB}(\alpha_{k} + f_{k},\rho_{k} = \frac{1 + \text{N}\pi_{k}\beta_{k}}{1 + \text{N}\beta_{k}})
\]</span></p>
where <span class="math inline">\(\pi_{k}\)</span> is the sampling fraction. In each local neighbourhood of cell <em>k</em> a smoothing polynomial regression model is carried out to estimate <span class="math inline">\(\alpha_{k}\)</span> and <span class="math inline">\(\beta_{k}\)</span>, and disclosure risk measures are estimated based on the Negative Binomial Distribution, <span class="math inline">\({\hat{\tau}}_{2} = \sum_{k \in \text{SU}}^{}{\hat{r_k} =}\sum_{k \in \text{SU}}^{}\frac{{\hat{\rho}}_{k}(1 - {\hat{\rho}}_{k})^{{\hat{\alpha}}_{k}}}{{\hat{\alpha}}_{k}(1 - {\hat{\rho}}_{k})}\)</span> , see: Rinott and Shlomo (2005, 2006).
</blockquote>
</section>
<section id="suda" class="level3">
<h3 class="anchored" data-anchor-id="suda">SUDA</h3>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Expert level</p>
</div>
</div>
</div>
<blockquote class="blockquote">
<p>The Special Uniques Detection Algorithm (SUDA) (Elliot et.al., 2005) is a software system (windows application available as freeware under restricted licence) that provides disclosure risk broken down by record, variable, variable value and by interactions of those. It is based on the concept of a “special unique”. A special unique is a record that is a sample unique on a set of variables and that is also unique on a subset of those variables. Empirical work has shown that special uniques are more likely to be population unique than random uniques. Special uniques can be classified according to the size and number of the smallest subset of key variables that defines the record as unique, known as minimal sample uniques (MSU). In the algorithm, all MSUs are found for each record on all possible subsets of the key variables where the maximum size of the subsets <em>m</em> is specified by the user.</p>
<p>SUDA grades and orders records within a microdata file according to the level of risk. The method assigns a per record matching probability to a sample unique based on the number and size of minimal uniques. The DIS Measure (Skinner and Elliot, 2000) is the conditional probability of a correct match given a unique match:</p>
<p><span class="math display">\[
p(cm \mid um) = \frac{\sum\limits_{k = 1}^{K} I\left(f_{k} = 1 \right)}{\sum\limits_{k = 1}^{K} F_{k} I \left(f_{k} = 1 \right) }
\]</span></p>
<p>and is estimated by a simple sample-based measure which is approximately unbiased without modelling assumptions. Elliot (2005) describes a heuristic which combines the DIS measure with scores resulting from the algorithm (i.e., SUDA scores). This method known as DIS-SUDA produces estimates of intruder confidence in a match against a given record being correct. This is closely related to the probability that the match is correct and is heuristically linked to the estimate of</p>
<p><span class="math display">\[
\tau_2 = \sum\limits_k{I(f_k=1)\frac{1}{F_k}}
\]</span></p>
<p>The advantage of this method is that it relates to a practical model of data intrusion, and it is possible to compare different values directly. The disadvantages are that it is sensitive to level of the max MSU parameter and is calculated in a heuristic manner. In addition it is difficult to compare disclosure risk across different files. However, the method has been extensively tested and was used successfully for the detection of high-risk records in the UK Sample of Anonymized Records (SAR) drawn from the 2001 Census (Merrett, 2004). The assessment showed that the DIS-SUDA measure calculated from the algorithm provided a good estimate for the individual disclosure risk measure, especially for the case when the number of key variables, <span class="math inline">\(m = 6\)</span>. The algorithm also identifies the variables and value of variables that are contributing most to the disclosure risk of the record.</p>
A new algorithm, SUDA2 has been developed, Elliot et al (2005), that improves SUDA using several methods. The development provides a much faster tool that can handle larger datasets.
</blockquote>
</section>
<section id="record-linkage" class="level3">
<h3 class="anchored" data-anchor-id="record-linkage">Record Linkage</h3>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Expert level</p>
</div>
</div>
</div>
<blockquote class="blockquote">
<p>Roughly speaking, record linkage consists of linking each record <span class="math inline">\(a\)</span> in file <span class="math inline">\(A\)</span> (protected file) to a record <span class="math inline">\(b\)</span> in file <span class="math inline">\(B\)</span> (original file). The pair <span class="math inline">\((a,b)\)</span> is a match if <span class="math inline">\(b\)</span> turns out to be the original record corresponding to <span class="math inline">\(a\)</span>.</p>
<p>To apply this method to measure the risk of identity disclosure, it is assumed that an intruder has got an external dataset sharing some (key or outcome) variables with the released protected dataset and containing additionally some identifier variables (<em>e.g.</em> passport number, full name, etc.). The intruder is assumed to try to link the protected dataset with the external dataset using the shared variables. The number of matches gives an estimation of the number of protected records whose respondent can be re-identified by the intruder. Accordingly, disclosure risk is defined as the proportion of matches among the total number of records in <span class="math inline">\(A\)</span>.</p>
The main types of record linkage used to measure identity disclosure in SDC are discussed below. An illustrative example can be found on the CASC-website as one of the case-studies linked to this handbook (see <a href="https://research.cbs.nl/casc/handbook.htm"><u>section handbook</u></a>).
</blockquote>
<section id="distance-based-record-linkage" class="level4">
<h4 class="anchored" data-anchor-id="distance-based-record-linkage">Distance-based record linkage</h4>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Expert level</p>
</div>
</div>
</div>
<blockquote class="blockquote">
<p>Distance-based record linkage consists of linking each record <span class="math inline">\(a\)</span> in file <span class="math inline">\(A\)</span> to its nearest record <span class="math inline">\(b\)</span> in file <span class="math inline">\(B\)</span>. Therefore, this method requires a definition of a distance function for expressing <em>nearness</em> between records. This record-level distance can be constructed from distance functions defined at the level of variables. Construction of record-level distances requires standardizing variables to avoid scaling problems and assigning each variable a weight on the record-level distance.</p>
<p>Distance-based record linkage was first proposed in Pagliuca and Seri (1999) to assess the disclosure risk after microaggregation, see section 3.4.2.3. Those authors used the Euclidean distance and equal weights for all variables. (Domingo-Ferrer and Torra , 2001) later used distance-based record linkage for evaluating other masking methods as well; in their empirical work, distance-based record linkage outperforms probabilistic record linkage (described below). Recently, (Torra and Miyamoto, 2004) have shown that method-specific distance functions might be defined to increase the proportion of matches for particular SDC methods.</p>
<p>The record linkage algorithm introduced in&nbsp;(Bacher, Brand and Bender, 2002) is similar in spirit to distance-based record linkage. This is so because it is based on cluster analysis and, therefore, links records that are near to each other.</p>
<p>The main advantages of using distances for record linkage are simplicity for the implementer and intuitiveness for the user. Another strong point is that subjective information (about individuals or variables) can be included in the re-identification process by properly modifying distances. In fact, the next version of the μ‑ARGUS microdata protection package (Hundepool et al., 2005) will incorporate distance-based record linkage as a disclosure risk assessment method.</p>
The main difficulty of distance-based record linkage consists of coming up with appropriate distances for the variables under consideration. For one thing, the weight of each variable must be decided and this decision is often not obvious. Choosing a suitable distance is also especially thorny in the cases of categorical variables and of masking methods such as local recoding where the masked file contains new labels with respect to the original dataset.
</blockquote>
</section>
<section id="probabilistic-record-linkage" class="level4">
<h4 class="anchored" data-anchor-id="probabilistic-record-linkage">Probabilistic record linkage</h4>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Expert level</p>
</div>
</div>
</div>
<blockquote class="blockquote">
<p>Like distance-based record linkage, probabilistic record linkage aims at linking pairs of records <span class="math inline">\((a,b)\)</span> in datasets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, respectively. For each pair, an index is computed. Then, two thresholds <span class="math inline">\(LT\)</span> and <span class="math inline">\(NLT\)</span> in the index range are used to label the pair as linked, clerical or non-linked pair: if the index is above <span class="math inline">\(LT\)</span>, the pair is linked; if it is below <span class="math inline">\(NLT\)</span>, the pair is non-linked; a clerical pair is one that cannot be automatically classified as linked or non-linked and requires human inspection. When independence between variables is assumed, the index can be computed from the following conditional probabilities for each variable: the probability <span class="math inline">\(\mathbb{P}\left( 1\mid M \right)\)</span> of coincidence between the values of the variable in two records <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> given that these records are a real match, and the probability <span class="math inline">\(\mathbb{P}\left( 0\mid U \right)\)</span>of non-coincidence between the values of the variable given that <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are a real unmatch.</p>
<p>Like in the previous section, disclosure risk is defined as the number of matches (linked pairs that are correctly linked) over the number of records in file <span class="math inline">\(A\)</span>.</p>
<p>To use probabilistic record linkage in an effective way, we need to set the thresholds <span class="math inline">\(LT\)</span> and <span class="math inline">\(NLT\)</span> and estimate the conditional probabilities <span class="math inline">\(\mathbb{P}\left( 1 \mid M \right)\)</span> and <span class="math inline">\(\mathbb{P}\left( 0 \mid U \right)\)</span> used in the computation of the indices. In plain words, thresholds are computed from: (i) the probability <span class="math inline">\(\mathbb{P}\left( \text{LP} \mid U \right)\)</span> of linking a pair that is an unmatched pair (a <em>false positive</em> or <em>false linkage</em>) and (ii) the probability <span class="math inline">\(\mathbb{P}\left( \text{NP} \mid M \right)\)</span>of not linking a pair that is a match (a <em>false negative</em> or <em>false unlinkage</em>). Conditional probabilities <span class="math inline">\(\mathbb{P}\left( 1 \mid M \right)\)</span> and <span class="math inline">\(\mathbb{P}\left( 0 \mid U \right)\)</span> are usually estimated using the EM algorithm (Dempster, Laird and Rubin 1977).</p>
<p>Original descriptions of this kind of record linkage can be found in Fellegi and Sunter (1969) and Jaro (1989). Torra and Domingo-Ferrer (2003) describe the method in detail (with examples) and Winkler (1993) presents a review of the state of the art on probabilistic record linkage. In particular, this latter paper includes a discussion concerning non-independent variables. A (hierarchical) graphical model has recently been proposed&nbsp;(Ravikumar and Cohen, 2004) that compares favourably with previous approaches.</p>
<p>Probabilistic record linkage methods are less simple than distance-based ones. However, they do not require rescaling or weighting of variables. The user only needs to provide two probabilities as input: the maximum acceptable probability <span class="math inline">\(\mathbb{P}\left( \text{LP} \mid U \right)\)</span> of false positive and the maximum acceptable probability <span class="math inline">\(\mathbb{P}\left( \text{NP} \mid M \right)\)</span> of false negative. </p>
</blockquote></section>
<section id="other-record-linkage-methods" class="level4">
<h4 class="anchored" data-anchor-id="other-record-linkage-methods">Other record linkage methods</h4>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Expert level</p>
</div>
</div>
</div>
<blockquote class="blockquote">
Recently, the use of other record linkage methods has also been considered for disclosure risk assessment. While in the previous record linkage methods it is assumed that the two files to be linked share a set of variables, other methods have been developed where this constraint is relaxed. Under appropriate conditions, (Torra, 2004) shows that re-identification is still possible when files do not share any variables. Domingo-Ferrer and Torra (2003) propose the use of such methods for disclosure risk assessment.
</blockquote>
</section>
</section>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<p>Bacher J., Brand R., and Bender S. (2002), <em>Re-identifying register data by survey data using cluster analysis: an empirical study</em>. International Journal of Uncertainty, Fuzziness and Knowledge Based Systems, 10(5):589–607, 2002.</p>
<p>Benedetti, R. and Franconi, L. (1998). <em>Statistical and technological solutions for controlled data dissemination,</em> Pre-proceedings of New Techniques and Technologies for Statistics, 1, 225-232.</p>
<p>Coppola, L. and Seri, G. (2005). <em>Confidentiality aspects of household panel survey: the case study of Italian sample from EU-SILC.</em> Monographs of official statistics – Proceedings of the Work session on statistical data confidentiality – Geneve 9-11 November 2005, 175-180.</p>
<p>Cox, L.H. (1995). <em>Protecting confidentiality in business surveys</em>. Business Survey Methods, Cox, B.G., Binder, D.A., Chinnappa, B.N., Christianson, A., Colledge, M.J. e Kott, P.S. (Eds.), New-York: Wiley, 443‑476.</p>
<p>Dempster A. P., Laird N. M., and Rubin D. B. (1977), <em>Maximum likelihood from incomplete data via the em algorithm.</em> Journal of the Royal Statistical Society, 39:1–38, 1977.</p>
<p>Deville, J.C. and Särndal, C.E. (1992). <em>Calibration estimators in survey sampling,</em> Journal of the American Statistical Association 87, 367–382.</p>
<p>Domingo-Ferrer J., and Torra, V. (2001), <em>A quantitative comparison of disclosure control methods for microdata.</em> In P.&nbsp;Doyle, J.&nbsp;I. Lane, J.&nbsp;J.&nbsp;M. Theeuwes, and L.&nbsp;Zayatz, editors, Confidentiality, Disclosure and Data Access: Theory and Practical Applications for Statistical Agencies, pages 111–134, Amsterdam, 2001. North-Holland. <a href="http://vneumann.etse.urv.es/publications/bcpi"><u>http://vneumann.etse.urv.es/publications/bcpi</u></a>.</p>
<p>Domingo-Ferrer, J., and Torra, V. (2003), <em>Disclosure risk assessment in statistical microdata protection via advanced record linkage.</em> Statistics and Computing, 13:343–354.</p>
<p>Elamir, E., Skinner, C. (2004) <em>Record-level Measures of Disclosure Risk for Survey Microdata,</em> Journal of Official Statistics (forthcoming). See also: Southampton Statistical Sciences Research Institute, University of Southampton, methodology working paper:<br>
<a href="http://eprints.soton.ac.uk/8175/01/s3ri-workingpaper-m04-02.pdf"><u>http://eprints.soton.ac.uk/8175/01/s3ri-workingpaper-m04-02.pdf</u></a></p>
<p>Elliot, M. J., (2000). <em>DIS: A new approach to the Measurement of Statistical Disclosure Risk.</em> International Journal of Risk Management 2(4), pp 39-48.</p>
<p>Elliot, M. J., Manning, A. M.&amp; Ford, R. W. (2002<strong>).</strong> '<em>A Computational Algorithm for Handling the Special Uniques Problem</em>'. International Journal of Uncertainty, Fuzziness and Knowledge Based Systems 5(10), pp 493-509.</p>
<p>Elliot, M. J., Manning, A., Mayes, K., Gurd, J. &amp; Bane, M. (2005). ’<em>SUDA: A Program for Detecting Special Uniques’.</em> Proceedings of the UNECE/Eurostat work session on statistical data confidentiality, Geneva, November 2005</p>
<p>Elliot, M. J., Skinner, C. J., and Dale, A. (1998). <em>'Special Uniques, Random Uniques, and Sticky Populations: Some Counterintuitive Effects of Geographical Detail on Disclosure Risk'</em>. Research in Official Statistics 1(2), pp 53-67.</p>
<p>Fellegi, I. P., and Sunter, A.B. (1969), <em>A theory for record linkage</em>. Journal of the American Statistical Association, 64(328):1183–1210.</p>
<p>Franconi, L. and Polettini, S. (2004). <em>Individual risk estimation in µ-ARGUS: a review.</em> In: Domingo-Ferrer, J. (Ed.), Privacy in Statistical Databases. Lecture Notes in Computer Science. Springer, 262‑272</p>
<p>Franconi, L. and Seri, G. (2000). <em>Microdata Protection at the Italian National Statistical Insititute (Istat): A User Perspective. Of Significance</em> Journal of the Association of Public Data Users – Volume 2 Number 1 2000, page. 57-64.</p>
<p>Hundepool, A., Van de&nbsp;Wetering, A., Ramaswamy, R., Franconi, L., Capobianchi, A., DeWolf, P.-P., Domingo-Ferrer, J., Torra, V., Brand, R., and Giessing, S. (2005), <em>µ-ARGUS version 4.0 Software and User’s Manual</em>. Statistics Netherlands, Voorburg NL, may 2005. <a href="http://neon.vb.cbs.nl/casc/deliv/MUmanual4.0.pdf"><u>https://research.cbs.nl/casc</u></a>.</p>
<p>Jackson, P., Longhurst, J. (2005), <em>Providing access to data and making microdata safe, experiences of the ONS</em>, proceedings of the UNECE/Eurostat work session on statistical data confidentiality, Geneva, November 2005</p>
<p>Jaro, M.A.&nbsp;(1989), <em>Advances in record-linkage methodology as applied to matching the 1985 census of tampa, florida.</em> Journal of the American Statistical Association, 84(406):414–420.</p>
<p>Pagliuca, D. and Seri, G. (1999), <em>Some results of individual ranking method on the system of enterprise accounts annual survey</em>, Esprit SDC Project, Deliverable MI-3/D2.</p>
<p>Polettini, S. and Seri, G (2004). <em>Revision of “Guidelines for the protection of social microdata using the individual risk methodology</em>”. Deliverable 1.2-D3, available at CASC web site.</p>
<p>Ravikumar, P., and Cohen, W.W. (2004),. <em>A hierarchical graphical model for record linkage.</em> In UAI 2004, USA, 2004. Association for Uncertainty in Artificial Intelligence.</p>
<p>Rinott, Y. ,Shlomo, N (2006) <em>A Generalized Negative Binomial Smoothing Model for Sample Disclosure Risk Estimation</em> ,. PSD'2006 Privacy in Statistical Databases, Springer LNCS proceedings, to appear.</p>
<p>Rinott, Y., Shlomo, N. (forthcoming) <em>A Smoothing Model for Sample Disclosure Risk Estimation</em>, Volume in memory of Yehuda Vardi in the IMS Lecture Notes Monograph Series.</p>
<p>Shlomo, N. (2006), <em>Review of statistical disclosure control methods for census frequency tables,</em> ONS Survey Methodology Bulletin.</p>
<p>Shlomo, N., Barton, J. (2006) <em>Comparison of Methods for Estimating Disclosure Risk Measures for Microdata at the UK Office for National Statistics</em>, PSD'2006 Privacy in Statistical Databases Conference, CD Proceedings, to appear</p>
<p>Skinner, C., Shlomo, N. (2005), <em>Assessing disclosure risk in microdata using record-level measures,</em> proceedings of the UNECE/Eurostat work session on statistical data confidentiality, Geneva, November 2005</p>
<p>Skinner, C.J., Shlomo, N. (2006) <em>Assessing Identification Risk in Survey Microdata Using Log-linear Models,</em> see: <a href="http://eprints.soton.ac.uk/41842/01/s3ri-workingpaper-m06-14.pdf" class="uri">http://eprints.soton.ac.uk/41842/01/s3ri-workingpaper-m06-14.pdf</a></p>
<p>Skinner, C., Holmes, D. (1998), <em>Estimating the re-identification risk per record in microdata,</em> JOS, Vol.14.</p>
<p>Torra, V. (2004), <em>Owa operators in data modeling and re-identification.</em> IEEE Trans. on Fuzzy Systems, vol.&nbsp;12, no. 5, pp.&nbsp;652-660.</p>
<p>Torra V., and Domingo-Ferrer J. (2003). <em>Record linkage methods for multidatabase data mining</em>. In V.&nbsp;Torra, editor, Information Fusion in Data Mining, pages 101–132, Germany, Springer.</p>
<p>Torra, V., and Miyamoto, S. (2004),. <em>Evaluating fuzzy clustering algorithms for microdata protection.</em> In J.&nbsp;Domingo-Ferrer and V.&nbsp;Torra, editors, Privacy in Statistical Databases, volume 3050 of LNCS, pages 175–186, Berlin Heidelberg. Springer.</p>
<p>Willenborg, L. and de Waal, T. (1996). <em>Statistical Disclosure Control in Practice.</em> Lecture Notes in Statistics, 111, New-York: Springer Verlag.</p>
<p>Willenborg, L. and de Waal, T. (2001). <em>Elements of statistical disclosure control.</em> Lecture Notes in Statistics, 115, New York: Springer-Verlag.</p>
<p>Winkler, W. E. (1993),. <em>Matching and record linkage.</em> Technical Report RR93/08, Statistical Research Division, U. S. Bureau of the Census (USA), 1993.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>