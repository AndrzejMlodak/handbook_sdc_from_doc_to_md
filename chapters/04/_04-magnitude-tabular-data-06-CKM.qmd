## Cell Key Method

The '\textit{Cell Key Method}' (CKM) was initially developed by the Australian Bureau of Statistics (Fraser/ Wooton (2016); Thompson et al. (2013)) and hence is sometimes referred to as '\textit{ABS method}'. It is a post tabular perturbative method that maintains consistency between all tables that use the same microdata and configuration. This method adds sufficient '\textit{noise}' to each cell so if an intruder tried to gather information by differencing, they would not be able to obtain the real data. It is one of the SDC methods recommended by Eurostat for the population and housing censuses 2021.
In order to keep consistency between tables every record of the underlying microdata is equipped with a randomly generated number, the so called '\textit{Record Key}'. This step is performed just once such that afterwards the Record Key is a fixed component of the microdata that is to be used for every subsequent evaluation. Now whenever the microdata are aggregated to form a table cell, the corresponding Record Keys are aggregated as well, forming the eponymous '\textit{Cell Key}'.
Using said Cell Key and a predefined table that encodes a probability distribution, which is tailored to the data/purpose, the corresponding noise can be looked up and added to the original cell value, before dissemination. 

Since the individual table cells are equipped with a noise independently, please note that this implies that the resulting table is no longer additive. For example, after perturbation, a population table could show that 1000 males, 1100 females and 16 non-binary persons live in an area, while the total count is 2109 persons. This non-additivity is part of the protective mechanism of this method and at the same time offers the advantage that the deviation from the original value can be kept as small as possible. It is not recommended to form such aggregates subsequently from perturbed values, because this would also add the sum of all noise terms to the aggregate, which can make the deviation uncontrollably large.

The Cell Key Method is a more informed post-tabular method of disclosure control since it utilizes pre-tabular microdata information during the perturbation stage. The method is highly dependent on the lookup table used, but it is flexible in that lookup tables can be specifically designed to meet needs, and different lookup tables could potentially be used for different tables. Furthermore, the lookup table can be designed to reflect other post-tabular methods (e.g. small cell adjustments or random rounding). The method provides protection for flexible tables and can be used to produce perturbations for large high dimensional hierarchical tables.
However, since perturbation is applied to each table cell independently, additivity gets lost. This is similar to the case of rounding but due to the complexity of the method, those inconsistencies in the data are harder to communicate.

Please note that there is not one ultimate way of how to define Record Key, Cell Key and the lookup table: The Australian Bureau of Statistics for example relies on integer values for their Record Keys whereas the Center of Excellence on SDC presented an approach where the Record Keys are uniformly distributed between 0 and 1, which should allow for more flexibility regarding noise design. We'll focus on the latter approach here, which is also implemented in $\tau$-Argus and the R-package '\textit{cellKey}'.
In the variant suggested by the CoE on SDC all digits before the decimal point are removed from the Cell Key, which makes it another random number that is uniformly distributed between 0 and 1. The lookup table now can be interpreted as the tabular representation of a piecewise constant inverse distribution function. By looking up values that are uniformly distributed, we thus obtain realizations of a random variable with the corresponding coded distribution.

It is possible to create lookup tables, which are also known as perturbation tables or p-tables, that are tailored to your needs, by using the freely accesible R-package '\textit{ptable}'. The package allows, among other things, to specify a maximum for the noise you want to add and the probability for the noise to be zero, which is equivalent to retaining the original value. You also have the option to generate the distribution, coded inside the perturbation table, in such a way, that certain values, such as ones or twos, do not occur in the perturbed output at all. The method for creating such tables, implemented in the \textit{ptable} package, is based on a maximum entropy approach as described, for example, in Giessing (2016) and yields a distribution with zero mean. Therefore, the distribution of the data will not get skewed by adding the noise. 
%For more information about the \textit{ptable} package, please see the vignette or the reference manual on cran. 
There are minor differences depending on whether the method is used for frequency tables or magnitude tables. 


### CKM for Magnitude Tables


The Cell Key Method was initially developed to protect frequency tables. By adding a controlled integer noise $v$ to a table cell $n$ a perturbed value $\hat{n}=n+v$ is generated. By applying this procedure to each table cell uncertainty about the real cell value is created. In this respect, this method has similar effects as rounding, but is unbiased and provides a higher level of protection when compared to a variant with similar level of information loss. A short comparison can be found in Enderle et al. (2018).

When adapting this method to magnitude tables, it must be noted that the amount of the noise $v$  needed, depends on the magnitude of the values in the microdata. Whereas in the case of frequencies it is a matter of protecting low counts and in particular individual cases, in the case of magnitude tables the magnitude of the individual values can vary a lot, and it is not sufficient, for example, to add a noise term of magnitude 5 when it is a matter of protecting a value that is one million. On the other hand, adding a noise term of one thousand to an original value of one hundred might be a little exaggerated. Since sufficient protection is particularly important in cases of dominance of one respondent, in the Cell Key Method for magnitude tables the amount of noise correlates with the size of the largest contribution to a cell value. So, if $x$ is the actual value of a cell, $x_{max}$ is the corresponding largest contribution and $v$ is a limited random noise variable with a discrete distribution, then the perturbed value $\hat{x}$ computes as $\hat{x}=x+\delta\cdot x_{max} \cdot v$, where $\delta$ is an additional control parameter. Since CKM derives its protective effect from uncertainty, all published values must of course be subject to some perturbation (with some probability). But since the amount of perturbation depends on the magnitude of the largest contribution, the deviations obtained are relatively small. Especially for cells without dominance issues, by adding (or subtracting) a fraction of the largest contribution value doesn’t affect the cell value too much. Whereas in table cells with a single strongly dominating contribution, the change in value is correspondingly more significant. But this is precisely what is desired.

The calculations for the Cell Key Method are normally carried out by appropriate software, such as $\tau$-Argus, so that the user does not have to perform them themselves. Nevertheless, in the following, we give a brief, rough overview of how CKM is applied to continuous data, for interested readers. More detailed explanations can be found in Gießing and Tent (2019). 

Since magnitudes usually aren’t integers but continuous, it is not possible to represent all values in a finite table. Hence an interpolation technique is used, while the p-table generally maintains the same form as depicted in Table \ref{tab:ckm_p_table}. Since we don’t want for a positive value $x$ to become negative after perturbation we require $0\leq\hat{x}=x+\delta\cdot x_{max} \cdot v$ which is equivalent to $v \geq (-x)/( \delta\cdot x_{max}) $. So $v$ has to be chosen with respect to $x/( \delta\cdot x_{max})$ and hence implicitly depends on both the cell value $x$ and the largest contributor $x_{max}$. Note, that in the case of frequency tables, the distribution of the noise $v$ depended only on the count $n$ to be perturbed, therefore, this value was used to look up the noise in the perturbation table. Accordingly, for the continuous case, the value $x/( \delta\cdot x_{max})$  is now used in the lookup step. We’ll use Table \ref{tab:ckm_p_table} again, to illustrate such a lookup step. If $x/( \delta\cdot x_{max})$  is one of the numbers 0, 1, 2, 3 or any value larger than 3, the lookup step works just as is the case of frequency tables. So if said value is 3, for example, and if the corresponding Cell Key is 0.8, again we have to look for that row in Table \ref{tab:ckm_p_table}, for which ‘\textit{orig. value}’ is 3 and for which $\textit{'lower bound'} < 0.8 \leq \textit{'upper bound'}$. Which again is met in the last table row, for which the noise is given as 1. Hence the perturbed value computes as $\hat{x}=x+\delta\cdot x_{max} \cdot 1$. Imagine now a true cell value $x=300$, with largest contributor $x_{max}=200$ and an additional control parameter of $\delta=0.5$. The corresponding result is then $\hat{x}=300+0.5\cdot 200 \cdot 1 = 400$. Please keep in mind that in this calculation example all values (including the p-table) are chosen in such a way that the calculation can be carried out as easily as possible and that the amount of noise is not anyway typical for practical use cases.

In case $x/( \delta\cdot x_{max})$  is a non-integer value smaller than 3, this value cannot be found in  Table \ref{tab:ckm_p_table}. To solve this issue interpolation is used, i.e. if $2 < x/( \delta\cdot x_{max}) < 3$, there exist some unique positive numbers $a$ and $b$ such that $x/( \delta\cdot x_{max}) = 2\cdot a + 3\cdot b$ and $a+b=1$. The algorithm, as implemented in $\tau$-Argus, for example, then computes both the noise $v_3$ for the case  $x/( \delta\cdot x_{max})=3$ and  the noise $v_2$ for the case  $x/( \delta\cdot x_{max})=2$. The correct noise is then computed as $ v_2\cdot a +  v_3\cdot b$. We already looked up the noise $v_3=1$, so we still need $v_2$. So once again we need to search Table \ref{tab:ckm_p_table}. After we spotted the row  for which ‘\textit{orig. value}’ equals 2 and for which $\textit{'lower bound'} < 0.8 \leq \textit{'upper bound'}$, we obtain a noise value of 0.

So if we consider the case where $x=300$, $x_{max}=200$ and $\delta=0.6$, then $x/( \delta\cdot x_{max}) = 2.5$ and this can be written as $2\cdot 0.5 + 3\cdot 0.5$. The perturbed value is therefore calculated as $\hat{x}=300+0.6\cdot 200 \cdot (v_2\cdot 0.5 + v_3\cdot 0.5) = 300+0.6\cdot 200 \cdot (0\cdot 0.5 + 1\cdot 0.5)=360$.

